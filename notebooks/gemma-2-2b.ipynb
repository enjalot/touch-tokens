{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enjalot/code/touch-tokens/ttenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x14afb8170>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some notes from SAE tutorial on gemmascope https://colab.research.google.com/drive/17dQFYUYnuKnP6OwQPH9v_GSYUW5aj-Rp#scrollTo=12wF3f7o1Ni7\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# this is what you do if you only want inference (not training)\n",
    "# saves on memory usage\n",
    "torch.set_grad_enabled(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 16.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# every transformer has a tokenizer, so we load the one for the model we want to use\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "# this downloads the model (or loads it from disk cache)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to study what's happening in the model when we run some input text through it\n",
    "input_text = \"hello, Yoda my name is\"\n",
    "# the first step is to tokenize the input text\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,  17534, 235269, 146433,    970,   1503,    603]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Token 2: \t\t<bos>\n",
      "1 Token 17534: \t\thello\n",
      "2 Token 235269: \t\t,\n",
      "3 Token 146433: \t\t Yoda\n",
      "4 Token 970: \t\t my\n",
      "5 Token 1503: \t\t name\n",
      "6 Token 603: \t\t is\n"
     ]
    }
   ],
   "source": [
    "def print_input(input_ids):\n",
    "  for i, t in enumerate(input_ids['input_ids'][0]):\n",
    "    print(f\"{i} Token {t}: \\t\\t{tokenizer.decode(t)}\")\n",
    "\n",
    "print_input(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tokens 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([     2,  17534, 235269, 146433,    970,   1503,    603, 146433,    578])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can run our model. Let's generate just 2 more tokens for now\n",
    "outputs = model.generate(**input_ids, max_new_tokens=2)\n",
    "print(\"output tokens\", len(outputs[0]))\n",
    "outputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, Yoda my name is Yoda and'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to turn the output tokens back into text (the output includes the input)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get hidden states for the input, we need to run the model again with the generated sequence\n",
    "hidden_output = model(**input_ids, output_hidden_states=True)\n",
    "\n",
    "# Access hidden states\n",
    "hidden_states = hidden_output.hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens 7\n",
      "hidden states (layers) 27\n",
      "hidden state shape torch.Size([1, 7, 2304])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"input tokens\", len(input_ids['input_ids'][0]))\n",
    "print(\"hidden states (layers)\", len(hidden_states))\n",
    "print(\"hidden state shape\", hidden_states[20].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma2ForCausalLM(\n",
      "  (model): Gemma2Model(\n",
      "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-25): 26 x Gemma2DecoderLayer(\n",
      "        (self_attn): Gemma2Attention(\n",
      "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
      "          (rotary_emb): Gemma2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Gemma2MLP(\n",
      "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
      "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
      "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
      "  (_cache): HybridCache()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in config: 26\n",
      "Hidden size: 2304\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of layers in config: {model.config.num_hidden_layers}\")\n",
    "print(f\"Hidden size: {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_residual_activations(model, target_layer, inputs):\n",
    "  \"\"\"\n",
    "  This function allows us to gather activations for a specific layer on a model.\n",
    "  \n",
    "  Args:\n",
    "  - model: The model from which we want to gather activations.\n",
    "  - target_layer: The specific layer index for which we want to gather activations.\n",
    "  - inputs: The input data to be passed through the model.\n",
    "  \n",
    "  Returns:\n",
    "  - target_act: The activations of the specified layer.\n",
    "  \"\"\"\n",
    "  target_act = None\n",
    "  def gather_target_act_hook(mod, inputs, outputs):\n",
    "    nonlocal target_act # make sure we can modify the target_act from the outer scope\n",
    "    target_act = outputs[0]\n",
    "    return outputs\n",
    "  # we could also easily target the MLP layer\n",
    "  # handle = model.model.layers[target_layer].mlp.register_forward_hook(gather_mlp_output_hook)\n",
    "  handle = model.model.layers[target_layer].register_forward_hook(gather_target_act_hook)\n",
    "  _ = model.forward(inputs)\n",
    "  handle.remove()\n",
    "  return target_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 20th index is actually the 21st layer\n",
    "target_act = gather_residual_activations(model, 20, input_ids['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 2304])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9440,  1.7632, -2.0879,  ...,  1.6978, -2.0868, -0.0178],\n",
       "         [-7.1130,  2.3935, -0.3611,  ..., -0.0207,  4.9698,  2.0012],\n",
       "         [-8.1484,  0.2589, -0.5944,  ..., -1.2177,  2.7641,  2.0122],\n",
       "         ...,\n",
       "         [ 1.5289, -3.7196,  7.7939,  ..., -9.8385,  0.1159,  0.6954],\n",
       "         [-3.1761,  1.1008,  0.5456,  ..., -1.7524, -2.0917,  2.4893],\n",
       "         [ 0.9512, -2.4978, -0.4893,  ..., -4.7208, -5.6637, -0.7142]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9440,  1.7632, -2.0879,  ...,  1.6978, -2.0868, -0.0178],\n",
       "         [-7.1130,  2.3935, -0.3611,  ..., -0.0207,  4.9698,  2.0012],\n",
       "         [-8.1484,  0.2589, -0.5944,  ..., -1.2177,  2.7641,  2.0122],\n",
       "         ...,\n",
       "         [ 1.5289, -3.7196,  7.7939,  ..., -9.8385,  0.1159,  0.6954],\n",
       "         [-3.1761,  1.1008,  0.5456,  ..., -1.7524, -2.0917,  2.4893],\n",
       "         [ 0.9512, -2.4978, -0.4893,  ..., -4.7208, -5.6637, -0.7142]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAE Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We download the weights for the SAE we want to use\n",
    "# https://www.neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=\"google/gemma-scope-2b-pt-res\",\n",
    "    filename=\"layer_20/width_16k/average_l0_71/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v) for k, v in params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class JumpReLUSAE(nn.Module):\n",
    "  def __init__(self, d_model, d_sae):\n",
    "    # Note that we initialise these to zeros because we're loading in pre-trained weights.\n",
    "    # If you want to train your own SAEs then we recommend using blah\n",
    "    super().__init__()\n",
    "    self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "    self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "    self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "    self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "    self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "  def encode(self, input_acts):\n",
    "    pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "    mask = (pre_acts > self.threshold)\n",
    "    acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "    return acts\n",
    "\n",
    "  def decode(self, acts):\n",
    "    return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "  def forward(self, acts):\n",
    "    acts = self.encode(acts)\n",
    "    recon = self.decode(acts)\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['W_dec'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_acts = sae.encode(target_act.to(torch.float32))\n",
    "reconstruction = sae.decode(sae_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 16384])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 2304])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6631, 14956, 10299, 15449, 11302,  8564, 15449]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, inds = sae_acts.max(-1)\n",
    "\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2028.7983,  122.3900,  107.6448,   90.2571,   89.6321,  102.8196,\n",
       "           42.7972]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 values shape: torch.Size([1, 7, 5])\n",
      "Top 5 indices shape: torch.Size([1, 7, 5])\n",
      "\n",
      "Top 5 values for first sequence item:\n",
      "tensor([2028.7983,  781.3959,  534.8594,  264.1917,  252.5279])\n",
      "\n",
      "Top 5 indices for first sequence item:\n",
      "tensor([ 6631,   743,  5052, 16057,  9479])\n"
     ]
    }
   ],
   "source": [
    "k = 5  # Change this to the number of top values you want\n",
    "values, indices = torch.topk(sae_acts, k, dim=-1)\n",
    "\n",
    "print(f\"Top {k} values shape: {values.shape}\")\n",
    "print(f\"Top {k} indices shape: {indices.shape}\")\n",
    "\n",
    "# Print the top k values and indices for the first sequence item\n",
    "print(f\"\\nTop {k} values for first sequence item:\")\n",
    "print(values[0, 0])\n",
    "print(f\"\\nTop {k} indices for first sequence item:\")\n",
    "print(indices[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=\"20-gemmascope-res-16k\", feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_release = \"gemma-2-2b\"\n",
    "layer = 20\n",
    "sae_id = f\"{layer}-gemmascope-res-16k\"\n",
    "feature_idx = 15449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/15449?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2a6e6ddc0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = get_dashboard_html(sae_release = sae_release, sae_id=sae_id, feature_idx=feature_idx)\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering_vector(sae, feature_index, scale=500, normalize=True):\n",
    "  sae_acts = torch.zeros(1, sae.W_dec.shape[0], device=sae.W_dec.device)\n",
    "  sae_acts[0, feature_index] = scale\n",
    "  steering = sae.decode(sae_acts)\n",
    "  if normalize:\n",
    "    steering = steering / torch.norm(steering, dim=-1, keepdim=True)\n",
    "  return steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modify_layer_activation(model, target_layer, input_ids, steering, scale, max_new_tokens):\n",
    "    \"\"\"\n",
    "    Modify the activation of a specific feature in a given layer.\n",
    "    \n",
    "    Args:\n",
    "    - model: The LLM model\n",
    "    - target_layer: The index of the layer to modify\n",
    "    - input_ids: The input token IDs\n",
    "    - sae: The Sparse Autoencoder\n",
    "    - feature_index: The index of the feature to modify\n",
    "    - modification_value: The value to add to the feature's activation\n",
    "    \n",
    "    Returns:\n",
    "    - modified_output: The model's output after modification\n",
    "    \"\"\"\n",
    "    def capture_and_modify_hook(module, inputs, outputs):\n",
    "        # Capture the original activation\n",
    "        original_act = outputs[0].detach()        \n",
    "        # Decode the modified activations\n",
    "        modified_act = original_act + steering * scale\n",
    "        # Return the modified activation\n",
    "        return (modified_act,) + outputs[1:]\n",
    "\n",
    "    # Register the hook\n",
    "    handle = model.model.layers[target_layer].register_forward_hook(capture_and_modify_hook)\n",
    "    \n",
    "    # Run the model with the modified activation\n",
    "    with torch.no_grad():\n",
    "        modified_output = model.generate(input_ids, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Remove the hook\n",
    "    handle.remove()\n",
    "    \n",
    "    return modified_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to study what's happening in the model when we run some input text through it\n",
    "input_text2 = \"Hello, my name is\"\n",
    "# the first step is to tokenize the input text\n",
    "input_ids2 = tokenizer(input_text2, return_tensors=\"pt\", add_special_tokens=True)\n",
    "max_new_tokens = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2 = model.generate(**input_ids2, max_new_tokens=max_new_tokens)\n",
    "generated_text2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = 20  # The layer you want to modify\n",
    "feature_index = 15449  # The feature index you want to modify\n",
    "modification_value = 500.0  # The value to add to the feature's activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2304])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering = get_steering_vector(sae, feature_index, modification_value)\n",
    "steering.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0153,  0.0034, -0.0012,  ..., -0.0239, -0.0238, -0.0027]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering2 = get_steering_vector(sae, feature_index, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0734e-03, -1.6376e-03,  6.5223e-03,  ..., -6.3663e-03,\n",
       "          1.2676e-02,  7.8327e-05]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001192092896"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(steering2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -9.4724,   2.1418,  -2.0042,  ..., -11.5200, -15.4272,  -1.4665])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = sae.W_dec[feature_index] * 500\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 1.2695, -0.3415,  1.3470,  ..., -1.2878,  2.6408,  0.0191],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = sae.b_dec\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0153,  0.0034, -0.0012,  ..., -0.0239, -0.0238, -0.0027])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(w + b) / torch.norm(w + b).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between steering and steering2: 0.369560\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between steering and steering2\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(steering, steering2, dim=1)\n",
    "\n",
    "print(f\"Cosine similarity between steering and steering2: {cosine_similarity.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Hello, my name is\n",
      "Original text: Hello, my name is Dr. David and I'm a professor of mathematics at the University of California, Davis. I\n",
      "Modified text: Hello, my name is Luke and I'm a Jedi. I' Star Wars, I's a Star Wars fan\n"
     ]
    }
   ],
   "source": [
    "strength = 400\n",
    "modified_output = modify_layer_activation(model, target_layer, input_ids2['input_ids'], steering, strength, max_new_tokens)\n",
    "\n",
    "# Generate text from the modified output\n",
    "modified_text = tokenizer.decode(modified_output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Input text:\", input_text2)\n",
    "print(\"Original text:\", generated_text2)\n",
    "print(\"Modified text:\", modified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breakdown(input_text, layer):\n",
    "  # combination of weights section\n",
    "  # we want to study what's happening in the model when we run some input text through it\n",
    "  \n",
    "  # the first step is to tokenize the input text\n",
    "  input_ids = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "  max_new_tokens = 1\n",
    "  outputs = model.generate(**input_ids, max_new_tokens=max_new_tokens)\n",
    "  generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "  print(\"Input text:\", input_text)\n",
    "  print(\"Generated text:\", generated_text)\n",
    "\n",
    "  target_act = gather_residual_activations(model, layer, input_ids['input_ids'])\n",
    "  sae_acts = sae.encode(target_act)\n",
    "\n",
    "  return input_text, input_ids, outputs, generated_text, target_act, sae_acts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: I took my dog to the vet\n",
      "Generated text: I took my dog to the vet for\n"
     ]
    }
   ],
   "source": [
    "dog = get_breakdown(\"I took my dog to the vet\", layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000, 22.9148,  ...,  0.0000,  0.0000, 23.6990],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog[0] # input text\n",
    "dog[1] # input ids\n",
    "dog[2] # outputs\n",
    "dog[3] # generated text\n",
    "dog[4] # target act\n",
    "dog[5] # sae acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Token 2: \t\t<bos>\n",
      "1 Token 235285: \t\tI\n",
      "2 Token 3895: \t\t took\n",
      "3 Token 970: \t\t my\n",
      "4 Token 5929: \t\t dog\n",
      "5 Token 577: \t\t to\n",
      "6 Token 573: \t\t the\n",
      "7 Token 13512: \t\t vet\n"
     ]
    }
   ],
   "source": [
    "print_input(dog[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_token_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog[5][0][dog_token_idx]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([87.1561, 73.1058, 62.1382, 55.6819, 42.4143, 41.5249, 32.7077, 31.0943,\n",
       "        29.6321, 28.7857, 25.7395, 25.6164, 25.5423, 24.0560, 23.7811, 23.5026,\n",
       "        22.5944, 22.0243, 21.5107, 20.5071, 20.4034, 19.6517, 19.4906, 19.4306,\n",
       "        19.2856, 19.2031, 18.7600, 18.6525, 18.0070, 17.9126, 17.5653, 17.4477]),\n",
       "indices=tensor([12082,  3717, 14838,  6631,  3940, 11640,  6299,  4949,  1692,  1596,\n",
       "        12468,  9768,  1089,  3645,  8476,  3461,  4418,  9251,  2860,   743,\n",
       "         8837,  9988,  4956, 15611,  4310,    49,  6381,  5052,  3567, 13130,\n",
       "        12001, 11700]))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(dog[5][0][dog_token_idx], k=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_features = torch.topk(dog[5][0][dog_token_idx], k=32).indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/3717?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2a819fa10>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = get_dashboard_html(sae_release=sae_release, sae_id=sae_id, feature_idx=dog_features[1])\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: I took my cat to the vet\n",
      "Generated text: I took my cat to the vet for\n",
      "0 Token 2: \t\t<bos>\n",
      "1 Token 235285: \t\tI\n",
      "2 Token 3895: \t\t took\n",
      "3 Token 970: \t\t my\n",
      "4 Token 4401: \t\t cat\n",
      "5 Token 577: \t\t to\n",
      "6 Token 573: \t\t the\n",
      "7 Token 13512: \t\t vet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([77.9781, 67.4630, 50.3103, 47.5962, 45.2936, 42.3410, 41.1088, 35.0701,\n",
       "        33.2441, 32.8526, 32.3556, 29.8324, 26.8098, 26.6279, 25.8563, 23.5551,\n",
       "        23.0960, 23.0918, 23.0880, 22.3735, 22.1612, 21.7123, 21.5312, 20.6601,\n",
       "        20.0952, 19.9142, 19.8482, 19.8014, 19.0374, 18.9671, 18.4707, 18.3619]),\n",
       "indices=tensor([ 3717,  6631,  6772,  3705, 11640,  3940, 12082,  1596,  1692,  6299,\n",
       "         8837,   743,    49,  4949,  9251,  4418,  3645,  9237,  9768,  8476,\n",
       "         9388, 12001, 11700, 12085, 13130,  2468,  2860, 11923,  4956, 14795,\n",
       "         5883,  9921]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = get_breakdown(\"I took my cat to the vet\", layer)\n",
    "cat[0] # input text\n",
    "cat[1] # input ids\n",
    "cat[2] # outputs\n",
    "cat[3] # generated text\n",
    "cat[4] # target act\n",
    "cat[5] # sae acts\n",
    "print_input(cat[1])\n",
    "cat_token_idx = 4\n",
    "cat[5][0][cat_token_idx]\n",
    "torch.topk(cat[5][0][cat_token_idx], k=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/6772?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2a81a7fb0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 - caregiving / pet relationship\n",
    "# 2, 3 - cat\n",
    "cat_features = torch.topk(cat[5][0][cat_token_idx], k=32).indices.tolist()\n",
    "html = get_dashboard_html(sae_release=sae_release, sae_id=sae_id, feature_idx=cat_features[2])\n",
    "IFrame(html, width=1200, height=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: I took my pet to the vet\n",
      "Generated text: I took my pet to the vet for\n",
      "0 Token 2: \t\t<bos>\n",
      "1 Token 235285: \t\tI\n",
      "2 Token 3895: \t\t took\n",
      "3 Token 970: \t\t my\n",
      "4 Token 7327: \t\t pet\n",
      "5 Token 577: \t\t to\n",
      "6 Token 573: \t\t the\n",
      "7 Token 13512: \t\t vet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([104.9154,  60.8711,  50.7887,  45.2049,  43.0934,  42.2413,  28.3095,\n",
       "         25.3525,  24.8617,  24.5862,  24.2275,  23.3301,  21.9932,  21.6487,\n",
       "         20.9348,  19.8659,  19.3494,  18.9593,  18.5117,  18.3310,  17.9691,\n",
       "         17.5346,  17.4015,  17.1198,  16.9894,  16.8812,  16.6862,  16.6782,\n",
       "         16.5374,  16.1531,  14.9676,  14.5475]),\n",
       "indices=tensor([14465,  1089,  3717, 15175,  6631, 12082,  9768,  9988,  1692, 10601,\n",
       "         3940,  3567, 11640,  6299,  3645, 15969,  7938,  1596,  8476,    49,\n",
       "        15572,  2012,  3404,   410,  4949,  5426,  2048, 13757,  3063,  5883,\n",
       "         6772,  6381]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet = get_breakdown(\"I took my pet to the vet\", layer)\n",
    "pet[0] # input text\n",
    "pet[1] # input ids\n",
    "pet[2] # outputs\n",
    "pet[3] # generated text\n",
    "pet[4] # target act\n",
    "pet[5] # sae acts\n",
    "print_input(pet[1])\n",
    "pet_token_idx = 4\n",
    "pet[5][0][pet_token_idx]\n",
    "torch.topk(pet[5][0][pet_token_idx], k=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/15175?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2a81525a0>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_features = torch.topk(pet[5][0][pet_token_idx], k=32).indices.tolist()\n",
    "html = get_dashboard_html(sae_release=sae_release, sae_id=sae_id, feature_idx=pet_features[3])\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: I took my tiger to the vet\n",
      "Generated text: I took my tiger to the vet today\n",
      "0 Token 2: \t\t<bos>\n",
      "1 Token 235285: \t\tI\n",
      "2 Token 3895: \t\t took\n",
      "3 Token 970: \t\t my\n",
      "4 Token 31469: \t\t tiger\n",
      "5 Token 577: \t\t to\n",
      "6 Token 573: \t\t the\n",
      "7 Token 13512: \t\t vet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([75.6183, 70.5476, 55.1671, 32.2650, 31.3126, 31.0271, 30.8081, 29.7397,\n",
       "        29.6808, 29.3874, 27.7411, 25.9877, 25.0921, 24.3694, 23.8438, 22.7950,\n",
       "        22.7310, 21.8632, 21.3663, 19.6248, 18.9306, 18.7682, 18.4276, 18.4126,\n",
       "        17.6487, 17.6335, 17.4958, 17.3650, 16.8088, 16.5935, 16.0777, 16.0739]),\n",
       "indices=tensor([ 6631,  8837, 11674,  3404,  6772,  4502, 11203,  7600,  2312, 15175,\n",
       "         1692,  9768,  3645,   743,  4591,  4503, 12084, 13353, 11038,  3717,\n",
       "         6161,  3019,  8476, 12284, 14804,  5400,  1416, 10805,  3567,  9193,\n",
       "         5299, 12599]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger = get_breakdown(\"I took my tiger to the vet\", layer)\n",
    "tiger[0] # input text\n",
    "tiger[1] # input ids\n",
    "tiger[2] # outputs\n",
    "tiger[3] # generated text\n",
    "tiger[4] # target act\n",
    "tiger[5] # sae acts\n",
    "print_input(tiger[1])\n",
    "tiger_token_idx = 4\n",
    "tiger[5][0][tiger_token_idx]\n",
    "torch.topk(tiger[5][0][tiger_token_idx], k=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/6772?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2a8152930>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger_features = torch.topk(tiger[5][0][tiger_token_idx], k=32).indices.tolist()\n",
    "html = get_dashboard_html(sae_release=sae_release, sae_id=sae_id, feature_idx=tiger_features[4])\n",
    "IFrame(html, width=1200, height=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_breakdown(\"I have a \", layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: I have a cat\n",
      "Generated text: I have a cat that\n",
      "0 Token 2: \t\t<bos>\n",
      "1 Token 235285: \t\tI\n",
      "2 Token 791: \t\t have\n",
      "3 Token 476: \t\t a\n",
      "4 Token 4401: \t\t cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([103.3880,  73.5215,  70.8671,  70.1262,  47.2687,  43.5433,  42.4167,\n",
       "         31.5071,  28.5573,  27.2919,  27.0627,  26.1791,  25.1344,  24.9358,\n",
       "         23.7866,  23.0588,  21.4485,  18.9834,  18.1445,  17.3769,  16.7656,\n",
       "         16.4360,  15.9879,  15.3771,  14.4296,  14.2035,  14.1157,  14.1082,\n",
       "         13.8757,  13.5338,  13.1257,  12.9537]),\n",
       "indices=tensor([ 3705,  6772,  6631,  8837, 14838, 14795, 15361,  9768, 11725,  3940,\n",
       "        12675,  7600,  1692,  3019,  7083, 13757,  8476, 12082,   743, 15509,\n",
       "         9988,  4197,  3645,  4039,  9388, 11104,  3174,  2468, 15572, 14859,\n",
       "         4310,  3404]))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihavecat = get_breakdown(\"I have a cat\", layer)\n",
    "ihavecat_token_idx = 4\n",
    "print_input(ihavecat[1])\n",
    "torch.topk(ihavecat[5][0][ihavecat_token_idx], k=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = get_dashboard_html(sae_release=sae_release, sae_id=sae_id, feature_idx=3717)\n",
    "# IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihavecat_act = ihavecat[4][0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8583, -2.8761, -7.3865,  ..., -1.6729, -3.3603, -4.7288])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihavecat_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = sae.encode(ihavecat_act)\n",
    "encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([103.3880,  73.5215,  70.8671,  70.1262,  47.2687,  43.5433,  42.4167,\n",
       "         31.5071,  28.5573,  27.2919,  27.0627,  26.1791,  25.1344,  24.9358,\n",
       "         23.7866,  23.0588]),\n",
       "indices=tensor([ 3705,  6772,  6631,  8837, 14838, 14795, 15361,  9768, 11725,  3940,\n",
       "        12675,  7600,  1692,  3019,  7083, 13757]))"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = torch.topk(encode, k=16)\n",
    "topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.8366,  0.2981,  0.9478,  ..., -3.1647,  1.7556,  1.5096]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering = get_steering_vector(sae, 3705, 103, False) + get_steering_vector(sae, 6772, 73, False) + get_steering_vector(sae, 6631, 70, False)+ get_steering_vector(sae, 8837, 70, False) - 3 * sae.b_dec\n",
    "steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.8366,  0.2981,  0.9478,  ..., -3.1647,  1.7556,  1.5096]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_tensor = get_steering_vector(sae, torch.tensor([3705, 6772, 6631, 8837]), torch.tensor([103., 73., 70., 70.]), False)\n",
    "steering_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0292, -0.6819, -1.5606,  ..., -0.9899, -1.2499, -3.0969]])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_topk = get_steering_vector(sae, topk.indices, topk.values, False)\n",
    "steering_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8106, -0.3835, -6.8812,  ..., -1.6010, -2.3316, -4.1605])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihavecat_sae = ihavecat[5][0][4]\n",
    "reconstruction = sae.decode(ihavecat_sae)\n",
    "reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9577\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity = torch.nn.functional.cosine_similarity(reconstruction, ihavecat_act.unsqueeze(0))\n",
    "print(f\"Cosine similarity: {cosine_similarity.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9157\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity = torch.nn.functional.cosine_similarity(steering_topk, ihavecat_act.unsqueeze(0))\n",
    "print(f\"Cosine similarity: {cosine_similarity.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.8293\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity = torch.nn.functional.cosine_similarity(steering_tensor, ihavecat_act.unsqueeze(0))\n",
    "print(f\"Cosine similarity: {cosine_similarity.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.8293\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity = torch.nn.functional.cosine_similarity(steering, ihavecat_act.unsqueeze(0))\n",
    "print(f\"Cosine similarity: {cosine_similarity.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between ihavecat_act and steering\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(steering_tensor, steering)\n",
    "print(f\"Cosine similarity: {cosine_similarity.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0165, -0.0119,  0.0168,  ..., -0.0133,  0.0365, -0.0012]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steer(\"I have a \", steering, layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
