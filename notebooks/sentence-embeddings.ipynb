{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enjalot/code/touch-tokens/ttenv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enjalot/code/touch-tokens/ttenv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the most downloaded sentence transformer on HuggingFace\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"This is an example sentence\", \"Here is an example sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each input sentence gets a 384 dimension embedding array associated with it\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.76568821e-02,  6.34958595e-02,  4.87130657e-02,  7.93049410e-02,\n",
       "        3.74480337e-02,  2.65276711e-03,  3.93748507e-02, -7.09845778e-03,\n",
       "        5.93614802e-02,  3.15370001e-02,  6.00980520e-02, -5.29051535e-02,\n",
       "        4.06067818e-02, -2.59308070e-02,  2.98427828e-02,  1.12691033e-03,\n",
       "        7.35149160e-02, -5.03819808e-02, -1.22386612e-01,  2.37028431e-02,\n",
       "        2.97265183e-02,  4.24768664e-02,  2.56337654e-02,  1.99519354e-03,\n",
       "       -5.69190867e-02, -2.71598585e-02, -3.29035483e-02,  6.60248846e-02,\n",
       "        1.19007066e-01, -4.58791442e-02, -7.26214424e-02, -3.25839929e-02,\n",
       "        5.23413643e-02,  4.50552590e-02,  8.25300720e-03,  3.67023498e-02,\n",
       "       -1.39415013e-02,  6.53919429e-02, -2.64272932e-02,  2.06431447e-04,\n",
       "       -1.36643406e-02, -3.62809524e-02, -1.95043329e-02, -2.89738476e-02,\n",
       "        3.94270346e-02, -8.84090513e-02,  2.62426864e-03,  1.36713749e-02,\n",
       "        4.83063087e-02, -3.11565604e-02, -1.17329173e-01, -5.11690117e-02,\n",
       "       -8.85287449e-02, -2.18962189e-02,  1.42986458e-02,  4.44167517e-02,\n",
       "       -1.34814698e-02,  7.43392408e-02,  2.66382713e-02, -1.98762454e-02,\n",
       "        1.79190915e-02, -1.06052868e-02, -9.04263109e-02,  2.13269182e-02,\n",
       "        1.41204864e-01, -6.47170749e-03, -1.40387495e-03, -1.53609905e-02,\n",
       "       -8.73571187e-02,  7.22173750e-02,  2.01402977e-02,  4.25587222e-02,\n",
       "       -3.49014290e-02,  3.19619518e-04, -8.02970380e-02, -3.27472314e-02,\n",
       "        2.85268147e-02, -5.13658151e-02,  1.09389201e-01,  8.19328204e-02,\n",
       "       -9.84039903e-02, -9.34095159e-02, -1.51292253e-02,  4.51248288e-02,\n",
       "        4.94171716e-02, -2.51867827e-02,  1.57077387e-02, -1.29290730e-01,\n",
       "        5.31896437e-03,  4.02343553e-03, -2.34572180e-02, -6.72982931e-02,\n",
       "        2.92280931e-02, -2.60845385e-02,  1.30625153e-02, -3.11663467e-02,\n",
       "       -4.82713543e-02, -5.58859594e-02, -3.87505740e-02,  1.20010823e-01,\n",
       "       -1.03924721e-02,  4.89704832e-02,  5.53537048e-02,  4.49359082e-02,\n",
       "       -4.00964357e-03, -1.02959730e-01, -2.92968471e-02, -5.83402216e-02,\n",
       "        2.70472448e-02, -2.20169518e-02, -7.22241551e-02, -4.13869359e-02,\n",
       "       -1.93298012e-02,  2.73331115e-03,  2.76936626e-04, -9.67587829e-02,\n",
       "       -1.00574732e-01, -1.41922822e-02, -8.07891563e-02,  4.53925468e-02,\n",
       "        2.45041009e-02,  5.97613826e-02, -7.38185421e-02,  1.19843744e-02,\n",
       "       -6.63403273e-02, -7.69044682e-02,  3.85157354e-02, -5.59361962e-33,\n",
       "        2.80013289e-02, -5.60784824e-02, -4.86601740e-02,  2.15569846e-02,\n",
       "        6.01980761e-02, -4.81403098e-02, -3.50246839e-02,  1.93313938e-02,\n",
       "       -1.75151750e-02, -3.89210097e-02, -3.81066673e-03, -1.70287509e-02,\n",
       "        2.82099731e-02,  1.28290178e-02,  4.71601374e-02,  6.21029735e-02,\n",
       "       -6.43588603e-02,  1.29285678e-01, -1.31231295e-02,  5.23069277e-02,\n",
       "       -3.73681188e-02,  2.89094504e-02, -1.68981031e-02, -2.37330254e-02,\n",
       "       -3.33491862e-02, -5.16763031e-02,  1.55356592e-02,  2.08803061e-02,\n",
       "       -1.25371031e-02,  4.59578969e-02,  3.72720584e-02,  2.80567314e-02,\n",
       "       -5.90005443e-02, -1.16988253e-02,  4.92182299e-02,  4.70328368e-02,\n",
       "        7.35487193e-02, -3.70529816e-02,  3.98458820e-03,  1.06412200e-02,\n",
       "       -1.61566844e-04, -5.27166203e-02,  2.75927614e-02, -3.92921753e-02,\n",
       "        8.44717696e-02,  4.86860462e-02, -4.85874340e-03,  1.79948192e-02,\n",
       "       -4.28569913e-02,  1.23375664e-02,  6.39954256e-03,  4.04822640e-02,\n",
       "        1.48887187e-02, -1.53941605e-02,  7.62947649e-02,  2.37043630e-02,\n",
       "        4.45237681e-02,  5.08195162e-02, -2.31253984e-03, -1.88737027e-02,\n",
       "       -1.23335915e-02,  4.66002338e-02, -5.63438311e-02,  6.29927143e-02,\n",
       "       -3.15535143e-02,  3.24912556e-02,  2.34673396e-02, -6.55437782e-02,\n",
       "        2.01709103e-02,  2.57082637e-02, -1.23868370e-02, -8.36498477e-03,\n",
       "       -6.64377660e-02,  9.43073928e-02, -3.57092842e-02, -3.42483222e-02,\n",
       "       -6.66351570e-03, -8.01527034e-03, -3.09711434e-02,  4.33012098e-02,\n",
       "       -8.21395312e-03, -1.50795057e-01,  3.07692457e-02,  4.00718711e-02,\n",
       "       -3.79293971e-02,  1.93211192e-03,  4.00530100e-02, -8.77074525e-02,\n",
       "       -3.68491970e-02,  8.57952889e-03, -3.19251530e-02, -1.25257978e-02,\n",
       "        7.35539347e-02,  1.34738453e-03,  2.05919165e-02,  2.71097925e-33,\n",
       "       -5.18577136e-02,  5.78360669e-02, -9.18985233e-02,  3.94421928e-02,\n",
       "        1.05576560e-01, -1.96912326e-02,  6.18402846e-02, -7.63464570e-02,\n",
       "        2.40880456e-02,  9.40049440e-02, -1.16535515e-01,  3.71198580e-02,\n",
       "        5.22425286e-02, -3.95853398e-03,  5.72214425e-02,  5.32855187e-03,\n",
       "        1.24016792e-01,  1.39022460e-02, -1.10249650e-02,  3.56052630e-02,\n",
       "       -3.30754779e-02,  8.16573873e-02, -1.52003784e-02,  6.05585128e-02,\n",
       "       -6.01397492e-02,  3.26102562e-02, -3.48296687e-02, -1.69881694e-02,\n",
       "       -9.74907577e-02, -2.71483343e-02,  1.74705847e-03, -7.68982247e-02,\n",
       "       -4.31858376e-02, -1.89985596e-02, -2.91661378e-02,  5.77488244e-02,\n",
       "        2.41821595e-02, -1.16901947e-02, -6.21434972e-02,  2.84351576e-02,\n",
       "       -2.37499102e-04, -2.51783077e-02,  4.39634686e-03,  8.12840387e-02,\n",
       "        3.64184454e-02, -6.04006201e-02, -3.65517363e-02, -7.93748051e-02,\n",
       "       -5.08530391e-03,  6.69699088e-02, -1.17784351e-01,  3.23743895e-02,\n",
       "       -4.71251979e-02, -1.34459799e-02, -9.48445201e-02,  8.24948307e-03,\n",
       "       -1.06748389e-02, -6.81882128e-02,  1.11814064e-03,  2.48019751e-02,\n",
       "       -6.35889545e-02,  2.84492429e-02, -2.61303335e-02,  8.58111531e-02,\n",
       "        1.14682287e-01, -5.35345674e-02, -5.63588105e-02,  4.26009037e-02,\n",
       "        1.09453909e-02,  2.09578834e-02,  1.00131221e-01,  3.26051787e-02,\n",
       "       -1.84208810e-01, -3.93208303e-02, -6.91454560e-02, -6.38105497e-02,\n",
       "       -6.56385794e-02, -6.41251029e-03, -4.79612499e-02, -7.68133178e-02,\n",
       "        2.95384265e-02, -2.29948610e-02,  4.17037010e-02, -2.50047334e-02,\n",
       "       -4.54507628e-03, -4.17136252e-02, -1.32289436e-02, -6.38358071e-02,\n",
       "       -2.46471167e-03, -1.37337586e-02,  1.68976486e-02, -6.30397871e-02,\n",
       "        8.98881108e-02,  4.18170691e-02, -1.85687393e-02, -1.80442150e-08,\n",
       "       -1.67998485e-02, -3.21577750e-02,  6.30384088e-02, -4.13092338e-02,\n",
       "        4.44818996e-02,  2.02469295e-03,  6.29592985e-02, -5.17373718e-03,\n",
       "       -1.00444080e-02, -3.05640418e-02,  3.52672487e-02,  5.58581464e-02,\n",
       "       -4.67124917e-02,  3.45102772e-02,  3.29577774e-02,  4.30114679e-02,\n",
       "        2.94361673e-02, -3.03164143e-02, -1.71107594e-02,  7.37485215e-02,\n",
       "       -5.47910072e-02,  2.77515464e-02,  6.20164676e-03,  1.58800595e-02,\n",
       "        3.42978872e-02, -5.15753590e-03,  2.35079527e-02,  7.53135681e-02,\n",
       "        1.92843471e-02,  3.36196609e-02,  5.09103388e-02,  1.52497068e-01,\n",
       "        1.64207872e-02,  2.70528402e-02,  3.75162624e-02,  2.18553618e-02,\n",
       "        5.66334017e-02, -3.95747498e-02,  7.12313503e-02, -5.41377105e-02,\n",
       "        1.03773852e-03,  2.11852770e-02, -3.56308781e-02,  1.09017007e-01,\n",
       "        2.76526506e-03,  3.13997380e-02,  1.38424430e-03, -3.45738046e-02,\n",
       "       -4.59277742e-02,  2.88083702e-02,  7.16907345e-03,  4.84684967e-02,\n",
       "        2.61018295e-02, -9.44075361e-03,  2.82169450e-02,  3.48723568e-02,\n",
       "        3.69098261e-02, -8.58949963e-03, -3.53205726e-02, -2.47856788e-02,\n",
       "       -1.91921405e-02,  3.80707420e-02,  5.99653833e-02, -4.22286727e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8809])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity between the two sentence embeddings\n",
    "# this is the foundation of all RAG stuff. basically embed your dataset\n",
    "# then embed a query and find the most similar embeddings in your dataset\n",
    "# then use the original text to answer the query\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(torch.tensor(embeddings[0]).unsqueeze(0), torch.tensor(embeddings[1]).unsqueeze(0))\n",
    "cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Sentence transformers library simplifies a lot of things for making embeddings\n",
    "# let's take a look at some of the stuff that goes on under the hood\n",
    "# this will be more like the LLM stuff\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enjalot/code/touch-tokens/ttenv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many sentence transformers models are based on the BERT architecture\n",
    "# though recently there are some based on LLMs \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
       "  \"architectures\": [\n",
       "    \"BertModel\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 384,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1536,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.45.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see here that hidden_size is 384, the dimensionality of the embeddings\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='sentence-transformers/all-MiniLM-L6-v2', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a key variable here is model_max_length=512, so that means the model can only handle up to 512 tokens\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do a single longer input to take a closer look at what happens with tokens\n",
    "# uncomment the second input to see truncation happen (its 233 * 3 tokens)\n",
    "inputs = [\n",
    "  \"\"\"\n",
    "  Books bombarded his shoulder, his arms, his upturned face.  A book lit, almost obediently, like a white pigeon, in his hands, wings fluttering.  In the dim, wavering light, a page hung open and it was like a snowy feather, the words delicately painted thereon.  In all the rush and fervor, Montage had only an instant to read a line, but it blazed in his mind for the next minute as if stamped there with fiery steel.  “Time has fallen asleep in the afternoon sunshine.”  He dropped the book.  Immediately, another fell into his arms.\n",
    "  \"\"\",\n",
    "  # \"\"\"\n",
    "  # The tent he lived in stood right smack up against the wall of the shallow, dull-colored forest separating his own squadron from Dunbar’ s.  Immediately alongside was the abandoned railroad ditch that carried the pipe that carried the aviation gasoline down to the fuel trucks at the airfield.  Thanks to Orr, his roommate, it was the most luxurious tent in the squadron.  Each time Yossarian returned from one of his holidays in the hospital or rest leaves in Rome, he was surprised by some new comfort Orr had installed in his absence - running water, wood-burning fireplace, cement floor.  Yossarian had chosen the site, and he and Orr had raised the tent to get her.  Orr, who was a grinning pygmy with pilot’s wings and thick, wavy brown hair parted in the middle, furnished all the knowledge, while Yossarian, who was taller, stronger, broader, and faster, did most of the work.  Just the two of them lived there, although the tent was big enough for six.  When summer came, Orr rolled up the side flaps to allow a breeze that never blew to flush away the air baking inside.\n",
    "  # The tent he lived in stood right smack up against the wall of the shallow, dull-colored forest separating his own squadron from Dunbar’ s.  Immediately alongside was the abandoned railroad ditch that carried the pipe that carried the aviation gasoline down to the fuel trucks at the airfield.  Thanks to Orr, his roommate, it was the most luxurious tent in the squadron.  Each time Yossarian returned from one of his holidays in the hospital or rest leaves in Rome, he was surprised by some new comfort Orr had installed in his absence - running water, wood-burning fireplace, cement floor.  Yossarian had chosen the site, and he and Orr had raised the tent to get her.  Orr, who was a grinning pygmy with pilot’s wings and thick, wavy brown hair parted in the middle, furnished all the knowledge, while Yossarian, who was taller, stronger, broader, and faster, did most of the work.  Just the two of them lived there, although the tent was big enough for six.  When summer came, Orr rolled up the side flaps to allow a breeze that never blew to flush away the air baking inside.\n",
    "  # The tent he lived in stood right smack up against the wall of the shallow, dull-colored forest separating his own squadron from Dunbar’ s.  Immediately alongside was the abandoned railroad ditch that carried the pipe that carried the aviation gasoline down to the fuel trucks at the airfield.  Thanks to Orr, his roommate, it was the most luxurious tent in the squadron.  Each time Yossarian returned from one of his holidays in the hospital or rest leaves in Rome, he was surprised by some new comfort Orr had installed in his absence - running water, wood-burning fireplace, cement floor.  Yossarian had chosen the site, and he and Orr had raised the tent to get her.  Orr, who was a grinning pygmy with pilot’s wings and thick, wavy brown hair parted in the middle, furnished all the knowledge, while Yossarian, who was taller, stronger, broader, and faster, did most of the work.  Just the two of them lived there, although the tent was big enough for six.  When summer came, Orr rolled up the side flaps to allow a breeze that never blew to flush away the air baking inside.\n",
    "  # \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(inputs, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "# basically we average the embeddings, but only for the tokens that are not padding tokens\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127, 384])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have an embedding for each token\n",
    "model_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pooling, average the embeddings for each token into a single embedding vector\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize embeddings\n",
    "# something we should explain... its often taken for granted or glossed over\n",
    "# but the embeddings are normalized to unit length\n",
    "# this is important for cosine similarity\n",
    "normalized_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
